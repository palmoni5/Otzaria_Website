import mongoose from 'mongoose';
import fs from 'fs';
import readline from 'readline';
import path from 'path';
import dotenv from 'dotenv';
import slugify from 'slugify';
import { fileURLToPath } from 'url';

dotenv.config({ path: '.env.local' });
dotenv.config({ path: '.env' });

const FILES_JSON_PATH = 'files.json';
const MESSAGES_JSON_PATH = 'messages.json';
const BACKUPS_JSON_PATH = 'backups.json';

// --- ×¡×›××•×ª ---
const UserSchema = new mongoose.Schema({
    name: { type: String, required: true, unique: true },
    email: { type: String, required: true, unique: true },
    password: { type: String, required: true },
    role: { type: String, enum: ['user', 'admin'], default: 'user' },
    points: { type: Number, default: 0 },
}, { timestamps: true });

const BookSchema = new mongoose.Schema({
    name: { type: String, required: true, unique: true },
    slug: { type: String, index: true },
    totalPages: { type: Number, default: 0 },
    completedPages: { type: Number, default: 0 },
    category: { type: String, default: '×›×œ×œ×™' },
    folderPath: { type: String },
}, { timestamps: true });

const PageSchema = new mongoose.Schema({
    book: { type: mongoose.Schema.Types.ObjectId, ref: 'Book', required: true },
    pageNumber: { type: Number, required: true },
    content: { type: String, default: '' },
    status: { type: String, enum: ['available', 'in-progress', 'completed'], default: 'available' },
    claimedBy: { type: mongoose.Schema.Types.ObjectId, ref: 'User' },
    claimedAt: { type: Date },
    completedAt: { type: Date },
    imagePath: { type: String, required: true },
}, { timestamps: true });

const UploadSchema = new mongoose.Schema({
    uploader: { type: mongoose.Schema.Types.ObjectId, ref: 'User', required: true },
    bookName: { type: String, required: true },
    originalFileName: { type: String },
    content: { type: String }, 
    status: { type: String, enum: ['pending', 'approved', 'rejected'], default: 'pending' },
    reviewedBy: { type: mongoose.Schema.Types.ObjectId, ref: 'User' },
}, { timestamps: true });

const MessageSchema = new mongoose.Schema({
    sender: { type: mongoose.Schema.Types.ObjectId, ref: 'User', required: true },
    recipient: { type: mongoose.Schema.Types.ObjectId, ref: 'User', default: null },
    subject: { type: String, default: '×œ×œ× × ×•×©×' },
    content: { type: String, required: true },
    isRead: { type: Boolean, default: false },
    replies: [{
      sender: { type: mongoose.Schema.Types.ObjectId, ref: 'User' },
      content: String,
      createdAt: { type: Date, default: Date.now }
    }]
}, { timestamps: true });

const User = mongoose.models.User || mongoose.model('User', UserSchema);
const Book = mongoose.models.Book || mongoose.model('Book', BookSchema);
const Page = mongoose.models.Page || mongoose.model('Page', PageSchema);
const Upload = mongoose.models.Upload || mongoose.model('Upload', UploadSchema);
const Message = mongoose.models.Message || mongoose.model('Message', MessageSchema);

// --- ×¢×–×¨×™× ---

async function loadDataFromFile(filePath) {
    if (!fs.existsSync(filePath)) {
        console.warn(`âš ï¸ File not found: ${filePath}`);
        return [];
    }
    const results = [];
    const fileStream = fs.createReadStream(filePath);
    const rl = readline.createInterface({ input: fileStream, crlfDelay: Infinity });

    console.log(`ğŸ“– Streaming ${filePath}...`);

    for await (const line of rl) {
        if (!line.trim()) continue;
        try {
            const doc = JSON.parse(line);
            results.push(doc);
        } catch (err) {}
    }

    if (results.length === 0) {
        try {
            const content = fs.readFileSync(filePath, 'utf8');
            const data = JSON.parse(content);
            if (Array.isArray(data)) return data;
            return [data];
        } catch (e) {}
    }
    return results;
}

function decodeFileName(encodedName) {
    try {
        const uriComponent = encodedName.replace(/_/g, '%');
        return decodeURIComponent(uriComponent);
    } catch (e) { return encodedName; }
}

function createHebrewSlug(name) {
    if (!name) return 'unknown';
    return name.trim().replace(/\s+/g, '-').replace(/[^\w\u0590-\u05FF\-]/g, '');
}

// ××¤×•×ª ×’×œ×•×‘×œ×™×•×ª
const userMap = new Map(); 
const bookMap = new Map(); 
const contentMap = new Map(); // fileName -> content

async function restore() {
    try {
        console.log('ğŸ”Œ Connecting to MongoDB...');
        await mongoose.connect(process.env.MONGODB_URI);
        console.log('âœ… Connected.');

        const rawFiles = await loadDataFromFile(FILES_JSON_PATH);
        const rawBackups = await loadDataFromFile(BACKUPS_JSON_PATH);
        const rawMessages = await loadDataFromFile(MESSAGES_JSON_PATH);
        const allMetadataSources = [...rawFiles, ...rawBackups];

        // ---------------------------------------------------------
        // ×©×œ×‘ 0: ×‘× ×™×™×ª ××¤×ª ×ª×•×›×Ÿ ×—×›××”
        // ---------------------------------------------------------
        console.log('ğŸ“ Building smart content cache...');
        rawFiles.filter(f => f.path && f.path.startsWith('data/content/')).forEach(fileRecord => {
            if (fileRecord.data && fileRecord.data.content) {
                // ×©××™×¨×ª ×”×ª×•×›×Ÿ ×ª×—×ª ×›×œ ×”××¤×ª×—×•×ª ×”××¤×©×¨×™×™×
                const rawName = path.basename(fileRecord.path); // _D7_90...txt
                const decodedName = decodeFileName(rawName);    // ××™×œ×ª ×”×©×—×¨...txt
                
                contentMap.set(rawName, fileRecord.data.content);
                contentMap.set(decodedName, fileRecord.data.content);
                
                // × ×¡×™×•×Ÿ ×œ×©××•×¨ ×’× ×‘×œ×™ ×¡×™×•××ª .txt ×œ××§×¨×” ×”×¦×•×¨×š
                contentMap.set(rawName.replace('.txt', ''), fileRecord.data.content);
                contentMap.set(decodedName.replace('.txt', ''), fileRecord.data.content);
            }
        });
        console.log(`âœ… Cached content for ${contentMap.size} keys.`);

        // ---------------------------------------------------------
        // ×©×œ×‘ 1: ××©×ª××©×™×
        // ---------------------------------------------------------
        const usersEntry = rawFiles.find(f => f.path === 'data/users.json');
        if (usersEntry && usersEntry.data) {
            for (const u of usersEntry.data) {
                const newId = new mongoose.Types.ObjectId();
                const existingUser = await User.findOne({ email: u.email });
                const finalId = existingUser ? existingUser._id : newId;
                
                userMap.set(u.id, finalId);
                const points = u.points?.$numberInt ? parseInt(u.points.$numberInt) : (u.points || 0);

                await User.updateOne(
                    { email: u.email },
                    {
                        $set: {
                            name: u.name,
                            password: u.password,
                            role: u.role,
                            points: points,
                            createdAt: u.createdAt ? new Date(u.createdAt) : new Date(),
                        },
                        $setOnInsert: { _id: finalId }
                    },
                    { upsert: true }
                );
            }
            console.log('âœ… Users imported.');
        }

        // ---------------------------------------------------------
        // ×©×œ×‘ 2: ×¡×¤×¨×™×
        // ---------------------------------------------------------
        const booksEntry = rawFiles.find(f => f.path === 'data/books.json');
        if (booksEntry && booksEntry.data) {
            for (const b of booksEntry.data) {
                const newId = new mongoose.Types.ObjectId();
                const slug = createHebrewSlug(b.name);
                
                const existingBook = await Book.findOne({ name: b.name });
                const finalId = existingBook ? existingBook._id : newId;

                bookMap.set(b.name, { _id: finalId, slug });
                const totalPages = b.totalPages?.$numberInt ? parseInt(b.totalPages.$numberInt) : (b.totalPages || 0);

                await Book.updateOne(
                    { name: b.name },
                    {
                        $set: {
                            slug: slug,
                            totalPages: totalPages,
                            folderPath: `/uploads/books/${slug}`,
                            createdAt: b.createdAt ? new Date(b.createdAt) : new Date()
                        },
                        $setOnInsert: { _id: finalId, completedPages: 0 }
                    },
                    { upsert: true }
                );
            }
            console.log('âœ… Books imported.');
        }

        // ---------------------------------------------------------
        // ×©×œ×‘ 3: ××™×—×•×™ ×“×¤×™×
        // ---------------------------------------------------------
        console.log('ğŸ§© Processing pages...');
        const pageOperations = [];
        const mergedPages = {};

        allMetadataSources.filter(f => f.path && f.path.startsWith('data/pages/')).forEach(fileRecord => {
            const bookName = path.basename(fileRecord.path, '.json');
            if (!fileRecord.data || !Array.isArray(fileRecord.data)) return;
            if (!mergedPages[bookName]) mergedPages[bookName] = {};

            const bookInfo = bookMap.get(bookName);
            const slugForThumb = bookInfo ? bookInfo.slug : createHebrewSlug(bookName);

            fileRecord.data.forEach(p => {
                const num = p.number?.$numberInt ? parseInt(p.number.$numberInt) : p.number;
                const defaultThumb = `/uploads/books/${slugForThumb}/page.${num}.jpg`;
                
                // ×—×™×¤×•×© ×ª×•×›×Ÿ ×œ×“×£ ×”×¡×¤×¦×™×¤×™ ×”×–×”
                // ×”×©× ×‘×“×¨×š ×›×œ×œ ×”×•×: "×©× ×¡×¤×¨_page_1.txt"
                const contentKey = `${bookName}_page_${num}.txt`;
                const content = contentMap.get(contentKey) || '';

                mergedPages[bookName][num] = {
                    ...mergedPages[bookName][num],
                    status: p.status,
                    claimedById: p.claimedById,
                    claimedAt: p.claimedAt,
                    completedAt: p.completedAt,
                    thumbnail: p.thumbnail || defaultThumb,
                    content: content
                };
            });
        });

        // ×¢×“×›×•×Ÿ ×“×¤×™× ×¢×œ ×‘×¡×™×¡ ×§×‘×¦×™ ×ª×•×›×Ÿ ×‘×œ×‘×“ (×× ×—×¡×¨ ××˜×-×“××˜×”)
        rawFiles.filter(f => f.path && f.path.startsWith('data/content/')).forEach(fileRecord => {
            const fileName = path.basename(fileRecord.path, '.txt');
            const decodedName = decodeFileName(fileName);
            const splitIndex = decodedName.lastIndexOf('_page_');
            
            if (splitIndex !== -1) {
                const bookName = decodedName.substring(0, splitIndex).trim();
                const pageNum = parseInt(decodedName.substring(splitIndex + 6));

                if (bookMap.has(bookName)) {
                    if (!mergedPages[bookName]) mergedPages[bookName] = {};
                    if (!mergedPages[bookName][pageNum]) {
                         const bookInfo = bookMap.get(bookName);
                         const slug = bookInfo ? bookInfo.slug : 'unknown';
                         mergedPages[bookName][pageNum] = { 
                            status: 'available',
                            thumbnail: `/uploads/books/${slug}/page.${pageNum}.jpg`
                        };
                    }
                    mergedPages[bookName][pageNum].content = fileRecord.data?.content || '';
                }
            }
        });

        const bookCompletedCounts = {};
        for (const [bookName, pagesObj] of Object.entries(mergedPages)) {
            const bookInfo = bookMap.get(bookName);
            if (!bookInfo) continue;
            bookCompletedCounts[bookInfo._id] = 0;

            for (const [pageNumStr, pageData] of Object.entries(pagesObj)) {
                let claimedByNewId = null;
                if (pageData.claimedById && userMap.has(pageData.claimedById)) {
                    claimedByNewId = userMap.get(pageData.claimedById);
                } else if (pageData.claimedById) {
                     claimedByNewId = userMap.values().next().value; 
                }

                if (pageData.status === 'completed') bookCompletedCounts[bookInfo._id]++;

                pageOperations.push({
                    book: bookInfo._id,
                    pageNumber: parseInt(pageNumStr),
                    content: pageData.content || '',
                    status: pageData.status || 'available',
                    claimedBy: claimedByNewId,
                    claimedAt: pageData.claimedAt ? new Date(pageData.claimedAt) : null,
                    completedAt: pageData.completedAt ? new Date(pageData.completedAt) : null,
                    imagePath: pageData.thumbnail
                });
            }
        }

        if (pageOperations.length > 0) {
            console.log(`Inserting ${pageOperations.length} pages...`);
            await Page.deleteMany({});
            const chunkSize = 500;
            for (let i = 0; i < pageOperations.length; i += chunkSize) {
                await Page.insertMany(pageOperations.slice(i, i + chunkSize));
                process.stdout.write('.');
            }
            console.log('\nâœ… Pages imported.');
        }

        for (const [bookId, count] of Object.entries(bookCompletedCounts)) {
            await Book.findByIdAndUpdate(bookId, { completedPages: count });
        }

        // ---------------------------------------------------------
        // ×©×œ×‘ 4: Uploads (×ª×™×§×•×Ÿ ×”×•×¨×“×•×ª)
        // ---------------------------------------------------------
        let uploadsData = [];
        const mainFileRecord = rawFiles.find(f => f.data && f.data.uploads && Array.isArray(f.data.uploads));
        
        if (mainFileRecord) {
             uploadsData = mainFileRecord.data.uploads;
        } else {
             rawFiles.forEach(f => {
                 if (f.uploads && Array.isArray(f.uploads)) uploadsData = uploadsData.concat(f.uploads);
                 if (f.data && f.data.uploads && Array.isArray(f.data.uploads)) uploadsData = uploadsData.concat(f.data.uploads);
             });
        }

        if (uploadsData.length > 0) {
            console.log(`ğŸ“‚ Processing ${uploadsData.length} uploads...`);
            await Upload.deleteMany({}); 

            const uploadsToInsert = uploadsData.map(u => {
                let uploaderId = null;
                if (u.uploadedById && userMap.has(u.uploadedById)) {
                    uploaderId = userMap.get(u.uploadedById);
                } else {
                    uploaderId = userMap.values().next().value;
                }

                // --- ×œ×•×’×™×§×” ××©×•×¤×¨×ª ×œ××¦×™××ª ×ª×•×›×Ÿ ---
                let realContent = '';
                
                // × ×¡×™×•×Ÿ 1: ×œ×¤×™ fileName (×‘×“×¨×š ×›×œ×œ ××§×•×“×“)
                if (u.fileName && contentMap.has(u.fileName)) {
                    realContent = contentMap.get(u.fileName);
                } 
                // × ×¡×™×•×Ÿ 2: ×œ×¤×™ originalFileName (×©× ×¢×‘×¨×™)
                else if (u.originalFileName && contentMap.has(u.originalFileName)) {
                    realContent = contentMap.get(u.originalFileName);
                }
                // × ×¡×™×•×Ÿ 3: ×”×ª×××” ××™×•×—×“×ª (×”×¡×¨×ª timestamps ×× ×™×©)
                else if (u.fileName) {
                    // ×œ××©×œ: name_timestamp.txt -> name.txt
                    const baseName = u.fileName.replace(/_\d+\.txt$/, '.txt');
                    if (contentMap.has(baseName)) realContent = contentMap.get(baseName);
                }
                
                // fallback ××—×¨×•×Ÿ
                const finalContent = realContent || u.content || "×”×ª×•×›×Ÿ ×œ× ×©×•×—×–×¨ ××”×’×™×‘×•×™.";

                return {
                    uploader: uploaderId,
                    bookName: u.bookName || '×¡×¤×¨ ×œ×œ× ×©×',
                    originalFileName: u.originalFileName || `upload.txt`,
                    content: finalContent,
                    status: u.status === 'approved' ? 'approved' : u.status === 'rejected' ? 'rejected' : 'pending',
                    reviewedBy: null, // ××¤×©×¨ ×œ×”×©××™×¨ ×¨×™×§
                    createdAt: u.uploadedAt ? new Date(u.uploadedAt) : new Date(),
                    updatedAt: new Date()
                };
            });

            await Upload.insertMany(uploadsToInsert);
            console.log('âœ… Uploads imported with content.');
        }

        // ---------------------------------------------------------
        // ×©×œ×‘ 5: ×”×•×“×¢×•×ª
        // ---------------------------------------------------------
        if (rawMessages && rawMessages.length > 0) {
            console.log(`ğŸ“¨ Importing messages...`);
            const messagesToInsert = [];
            for (const msg of rawMessages) {
                const senderId = userMap.get(msg.senderId);
                const replies = (msg.replies || []).map(r => ({
                    sender: userMap.get(r.senderId),
                    content: r.message,
                    createdAt: r.createdAt ? new Date(r.createdAt) : new Date()
                })).filter(r => r.sender);

                if (senderId) {
                    messagesToInsert.push({
                        sender: senderId,
                        subject: msg.subject || '×œ×œ× × ×•×©×',
                        content: msg.message,
                        isRead: !!msg.readAt,
                        replies: replies,
                        createdAt: msg.createdAt ? new Date(msg.createdAt) : new Date()
                    });
                }
            }
            await Message.deleteMany({});
            await Message.insertMany(messagesToInsert);
            console.log('âœ… Messages imported.');
        }

        console.log('ğŸ‰ RESTORE COMPLETE!');
        process.exit(0);

    } catch (error) {
        console.error('âŒ Error during restore:', error);
        process.exit(1);
    }
}

restore();